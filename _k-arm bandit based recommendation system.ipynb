{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df2a0a4",
   "metadata": {},
   "source": [
    "# k-arm bandit based recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309985eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2010b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    def __init__(self, k=10, epsilon=0.1, initial_reward=0.0):\n",
    "        self.k = k \n",
    "        self.epsilon = epsilon\n",
    "        self.q_values = np.full(k, initial_reward)  \n",
    "        self.action_counts = np.zeros(k)  \n",
    "\n",
    "    def select_item(self):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.k)\n",
    "        else:\n",
    "            return np.argmax(self.q_values)\n",
    "\n",
    "    def update_estimates(self, action, reward):\n",
    "        self.action_counts[action] += 1\n",
    "        alpha = 1 / self.action_counts[action] \n",
    "        self.q_values[action] += alpha * (reward - self.q_values[action])\n",
    "\n",
    "    def run(self, true_rewards, steps=1000):\n",
    "        rewards = []\n",
    "        for step in range(steps):\n",
    "            action = self.select_item()\n",
    "            reward = np.random.normal(true_rewards[action], 1)\n",
    "            self.update_estimates(action, reward)\n",
    "            rewards.append(reward)\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c34f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 15\n",
    "epsilon = 0.1\n",
    "true_rewards = np.random.normal(0, 1, k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff438088",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = RecommendationSystem(k=k, epsilon=epsilon)\n",
    "rewards = recommender.run(true_rewards, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb0ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated rewards for items: [ 0.35282296  1.57206815  0.63284933  3.19346708 -0.39117545  0.96970638\n",
      "  1.11953268  1.19600778  0.26623694  0.19550834 -0.87818413  0.07256211\n",
      "  1.06697449  0.6053049   0.8131404 ]\n",
      "True rewards for items: [-0.12298806  1.46944141  0.78836644  3.16393251  0.30763008  0.40905649\n",
      "  1.12646632  0.99933533  0.37411844  0.07443958 -0.65374475  0.75409298\n",
      "  1.76732288 -0.25753264  0.83635296]\n"
     ]
    }
   ],
   "source": [
    "print(\"Estimated rewards for items:\", recommender.q_values)\n",
    "print(\"True rewards for items:\", true_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92fd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
